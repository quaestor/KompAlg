\section*{Aufwand für banale und schnelle Exponentiation im Vergleich}
\addcontentsline{toc}{subsection}{Aufwand für banale und schnelle
Exponentiation im Vergleich}

%%%
% Angabe
%%%
\subsection*{Angabe}
Betrachten Sie in dieser Aufgabe die Exponentiation im Bereich der natürlichen
Zahlen (die Argumente übertragen sich auf andere Halbgruppen, aber das ist
weniger relevant).

Für $a \in \mathbb{N}$ bezeichne $\|a\|$ die ``Größe'' von $a$, also  $\|a\| =
\log|a|$  = die Anzahl der Ziffern in der Binärdarstellung von $a$. Sie wissen
(oder überzeigen sich davon),
\begin{itemize}
\item
dass sich die \underline{Größe} bei der Multiplikation additiv verhält, d.h.
$\|a*b\|=\|a\|+\|b\|$ \\(also insbesondere gilt bei Exponentiation: $\|a^k\|= k
\cdot \|a\|$);
\item
dass der \underline{Aufwand} für eine  Multiplikation $(a,b) \mapsto a*b$
multiplikativ  von den Größen der Operanden abhängt, d.h.  wie $c \cdot \|a\|
\cdot \|b\|$ mit einer Konstanten $c$. Das gilt jedenfalls für die
``Schulmethode''.  Der Einfachheit halber können Sie $c=1$ annehmen.
\end{itemize}

Sei nun $a \in \mathbb{N}$ und $N = 2^n-1$. Betrachten Sie die Aufgabe, die
Zahl $a^N = a^{2^n-1}$ zu berechnen.  Man kann das entweder mit der ``banalen''
oder mit der ``schnellen'' Methode machen:

\begin{itemize}
\item[a)]
\begin{algorithmic}
\STATE{$x \leftarrow a$}
\FOR{$i$ from $1$ to $N-1$}
\STATE{$x \leftarrow x*a$}
\ENDFOR
\STATE{Return($x$)}
\end{algorithmic}

\item[b)]
\begin{algorithmic}
\STATE{$x \leftarrow a, y \leftarrow a$}
\FOR{$i$ from $1$ to $n-1$}
\STATE{$y \leftarrow y*y$}
\STATE{$x \leftarrow x*y$}
\ENDFOR
\STATE{Return($x$)}
\end{algorithmic}
\end{itemize}

Beachten Sie: die \underline{Anzahl} der Schleifendurchläufe bei Algorithmus a)
ist exponentiell größer als die bei Algorithmus b).  Entsprechend ist die
\underline{Anzahl} der Multiplikationen bei Algorithmus a) gleich $N-1$ und bei
Algorithmus b) gleich $2(n-1)$, ebenfalls ein exponentieller Sprung.

\begin{flushenum}
\item Zeigen Sie, dass der Algorithmus b) korrekt ist!
\item Bestimmen Sie nun den Aufwand der beiden Verfahren, indem Sie
	feststellen, welche Operanden in den jeweiligen Schleifendurchläufen
	miteinander multipliziert werden, wie gross sie sind und was die
	Multiplikation in Abhängigkeit von ihrer Größe demnach kostet.\\
	Hinweis: Sie sollten herausfinden, dass die Kosten in beiden Fällen
	$\mathcal{O}(N^2)$ betragen!
\end{flushenum}

%%%
% Lösung
%%%
\subsection*{Lösung}
\begin{flushenum}
\item
  Aus dem Algorithmus ergeben sich die rekursiven Folgen
  \[ y_{n}^{'} = (a^{2^{n}})_{n\geq 0} \]
  \[ x_{n}^{'} = x_{n-1}^{'} \cdot y_{n}^{'}, \quad x_{0}^{'} = a \]
  Betrachtet man nur die Exponenten so erhält man
  \[ y_{n} = 2y_{n-1} \]
  \[ x_{n} = x_{n-1} + y_{n} \]
  mit den Rekursionspolynomen
  \[ a_{y}(z) = 1 - 2z \]
  sowie
  \[ a_{x}(z) = 1 - z \]
  für den homogenen Teil von $(x_{n})$.
  Laut Skript $3.11$ (Kap. $3$) genügt die inhomogene Rekursion $(x_{n})$ einer
  homogenen Rekursion mit Rekursionspolynom
  \[ a_{x}(z) \cdot a_{y}(z) = (1 - z)(1 - 2z) = 1 - 3z + 2z^{2} \]
  und zugehörigem charakteristischen Polynom
  \[ \chi(z)= z^{2} - 3z + 2 = (z - 1)(z - 2) \]
  also den Eigenwerten $1$ und $2$; in Exponentialsummendarstellung:
  \[ x_{n} = \alpha_{1}1^{n} + \alpha_{2}2^{n} \]
  Mit den aus dem Algorithmus offensichtlichen Startwerten für die Exponenten
  ergeben sich folgende Werte für $\alpha_{1}$ und $\alpha_{2}$:
  \[ \begin{pmatrix} \alpha_{1} & \alpha_{2} \end{pmatrix} 
     \begin{pmatrix} 1 & 1 \\ 1 & 2 \end{pmatrix} = \begin{pmatrix} 0 & 1
     \end{pmatrix} \]
  \[ \alpha_{1} = -1, \quad \alpha_{2} = 1 \]
  \[ \Rightarrow x_{n} = 2^{n} - 1 \]
  Der Algorithmus ist also korrekt und berechnet $a^{2^{n}-1}$
\item
  Mit der Definition des Aufwands ($c = 1$) für eine Multiplikation aus der
  Angabe gilt für den Aufwand $t_a$ des Algorithmus a)
  \begin{align*}
	  t_a(N) & = \sum_{i=1}^{N-1} \|x_i\| \cdot \|a\| = \sum_{i=1}^{N-1} \|a^i\|
	  \cdot \|a\| = \|a\|^2 \sum_{i=1}^{N-1} i = \|a\|^2 \frac{N(N-1)}{2} \in
	  \mathcal{O}(N^2). \\
	  \intertext{\noindent Analog verfährt man mit Algorithmus b):}
	  t_b(n) & = \sum_{i=1}^{n-1} \|y_{i-1}\| \cdot \|y_{i-1}\| + \|x_i\|
	  \cdot \|y_i\| = \sum_{i=1}^{n-1} \|a^{2^{i-1}}\|^2 + \|a^{2^i - 1}\|
	  \cdot \|a^{2^i}\| \\
	  & = \|a\|^2 \sum_{i=1}^{n-1} 2^{2(i-1)} + 2^{2i} - 2^i \\
	  \intertext{\noindent Einzeln summieren und zusammenfassen ergibt}
	  & = \|a\|^2 \left(\frac{5}{12}4^n -2^n -\frac{1}{3}\right)
	  = \frac{\|a\|^2}{12} \left(5N^2 - 2N - 3\right) \in
	  \mathcal{O}(N^2).
  \end{align*}
  Man sieht folglich, dass der Aufwand für beide Algorithmen quadratisch im
  Exponenten ist. Der eigentliche Vorteil von Algorithmus b) zeigt sich jedoch,
  wenn man Multiplikationen von Zahlen fester Länge betrachtet, beispielsweise
  $32$-bit-Multiplikationen. Dann spielt für den Aufwand lediglich die Anzahl
  der Multiplikationen eine Rolle, die, wie in der Angabe bereits bemerkt,
  exponentiell kleiner ist als bei Algorithmus a).
\end{flushenum}
